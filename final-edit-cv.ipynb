{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45fe0020-62b8-4b59-a26b-762c409d7b29",
      "metadata": {
        "id": "45fe0020-62b8-4b59-a26b-762c409d7b29"
      },
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# Final Team Project - Full Machine Learning Pipeline\n",
        "# ===========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix,\n",
        "    ConfusionMatrixDisplay, roc_curve, auc\n",
        ")\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent storage of data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkMPmQhWej4u",
        "outputId": "bea98d76-b235-466f-a995-928bace2b5f0"
      },
      "id": "rkMPmQhWej4u",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/ADS-504-Final-Project')"
      ],
      "metadata": {
        "id": "8Er234YSlLGG",
        "outputId": "61c443cc-013f-42e3-86af-ce25e4553c84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8Er234YSlLGG",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW GOOGLE COLAB FILE PATHS ===\n",
        "train_path = r\"\\content\\drive\\My Drive\\Colab Notebooks\\ADS-504-Final-Project\\adult.data\"\n",
        "test_path = r\"\\content\\drive\\My Drive\\Colab Notebooks\\ADS-504-Final-Project\\adult.test\""
      ],
      "metadata": {
        "id": "UePz9o0-mDSI"
      },
      "id": "UePz9o0-mDSI",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e2dc81-b244-44b9-a050-eb8722b0017d",
      "metadata": {
        "id": "71e2dc81-b244-44b9-a050-eb8722b0017d"
      },
      "outputs": [],
      "source": [
        "# === FILE PATHS ===\n",
        "train_path = r\"C:\\Users\\User\\Downloads\\census+income\\adult.data\"\n",
        "test_path = r\"C:\\Users\\User\\Downloads\\census+income\\adult.test\"\n",
        "\n",
        "# === COLUMN NAMES ===\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
        "    \"hours_per_week\", \"native_country\", \"income\"\n",
        "]\n",
        "\n",
        "# === 1. DATASET INTRODUCTION ===\n",
        "print(\"üìå PROJECT INTRODUCTION:\")\n",
        "print(\"\"\"\n",
        "The goal of this project is to predict whether an individual earns more than $50K per year\n",
        "based on demographic and employment attributes from the UCI Adult Census dataset.\n",
        "\n",
        "This problem is important because it demonstrates how demographic and employment features\n",
        "can be leveraged to identify income patterns. Machine learning models can help in policy-making,\n",
        "targeted services, and socio-economic research by revealing key factors that influence income levels.\n",
        "\"\"\")\n",
        "\n",
        "# === LOAD DATA ===\n",
        "df_train = pd.read_csv(train_path, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "df_test = pd.read_csv(test_path, header=0, names=columns, na_values=\" ?\", skipinitialspace=True, comment='|')\n",
        "df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "# === VARIABLE DESCRIPTIONS ===\n",
        "var_desc = pd.DataFrame({\n",
        "    \"Feature\": columns,\n",
        "    \"Description\": [\n",
        "        \"Age of the individual\",\n",
        "        \"Type of employment\",\n",
        "        \"Census final weight (sample size indicator)\",\n",
        "        \"Highest level of education attained\",\n",
        "        \"Number of years of education\",\n",
        "        \"Marital status\",\n",
        "        \"Occupation type\",\n",
        "        \"Relationship status\",\n",
        "        \"Race\",\n",
        "        \"Gender\",\n",
        "        \"Capital gain\",\n",
        "        \"Capital loss\",\n",
        "        \"Average hours worked per week\",\n",
        "        \"Country of origin\",\n",
        "        \"Income class (<=50K or >50K)\"\n",
        "    ],\n",
        "    \"Type\": [\"Numeric\", \"Categorical\", \"Numeric\", \"Categorical\", \"Numeric\", \"Categorical\",\n",
        "             \"Categorical\", \"Categorical\", \"Categorical\", \"Categorical\", \"Numeric\",\n",
        "             \"Numeric\", \"Numeric\", \"Categorical\", \"Target\"]\n",
        "})\n",
        "print(\"\\nüìä Variable Descriptions:\")\n",
        "print(var_desc)\n",
        "\n",
        "# === 2. PREPROCESSING ===\n",
        "print(\"\\nüßπ PREPROCESSING STARTED...\")\n",
        "\n",
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove extra spaces\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Fix target variable encoding\n",
        "df[\"income\"] = df[\"income\"].replace({\">50K.\": \">50K\", \"<=50K.\": \"<=50K\"}).map({\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "print(f\"‚úÖ Data cleaned. New shape: {df.shape}\")\n",
        "\n",
        "# Save cleaned raw dataset\n",
        "df.to_csv(r\"C:\\Users\\User\\Downloads\\census+income\\cleaned_raw_full.csv\", index=False)\n",
        "\n",
        "# === 3. EXPLORATORY DATA ANALYSIS (EDA) ===\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Income distribution\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.countplot(x=\"income\", data=df)\n",
        "plt.title(\"Income Distribution\")\n",
        "plt.show()\n",
        "print(\"\\nüîç Insight: The dataset is imbalanced, with the majority earning <=50K.\")\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "print(\"üîç Insight: Education_num, capital_gain, and hours_per_week have the strongest positive correlation with income.\")\n",
        "\n",
        "# === 4. ENCODING & SCALING ===\n",
        "df_encoded = pd.get_dummies(df, columns=[\n",
        "    \"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
        "    \"relationship\", \"race\", \"sex\", \"native_country\"\n",
        "])\n",
        "\n",
        "# Scale numeric features EXCEPT target\n",
        "numeric_cols = df_encoded.select_dtypes(include=np.number).columns.tolist()\n",
        "features_to_scale = [col for col in numeric_cols if col != \"income\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_encoded[features_to_scale] = scaler.fit_transform(df_encoded[features_to_scale])\n",
        "\n",
        "# Save modeling-ready dataset\n",
        "df_encoded.to_csv(r\"C:\\Users\\User\\Downloads\\census+income\\cleaned_data_encoded_scaled.csv\", index=False)\n",
        "\n",
        "# === 5. TRAIN/TEST SPLIT ===\n",
        "X = df_encoded.drop(\"income\", axis=1)\n",
        "y = df_encoded[\"income\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 6. MODELING & VALIDATION ===\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"CV Mean Accuracy\": cv_scores.mean(),\n",
        "        \"Test Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC\": auc_score\n",
        "    })\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"Cross-Validation Accuracy (Mean ¬± Std): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=[\"<=50K\", \">50K\"]).plot(\n",
        "        cmap='Blues' if name==\"Logistic Regression\" else 'Greens'\n",
        "    )\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc(fpr, tpr):.2f})\")\n",
        "\n",
        "# === 7. ROC Curve Comparison ===\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# === 8. MODEL PERFORMANCE COMPARISON TABLE ===\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nüìä Model Performance Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# === 9. BEST MODEL SELECTION & INSIGHTS ===\n",
        "best_model = results_df.sort_values(by=\"Test Accuracy\", ascending=False).iloc[0]\n",
        "print(f\"\\n‚úÖ Best performing model: {best_model['Model']} \"\n",
        "      f\"with {best_model['Test Accuracy']:.4f} accuracy and {best_model['AUC']:.4f} AUC.\")\n",
        "print(\"üí° Insight: Logistic Regression is easier to interpret, \"\n",
        "      \"while Random Forest may capture complex feature interactions better.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7af84e5b"
      },
      "source": [
        "After running the cell above and successfully mounting your Google Drive, run the following code to update the file paths in the first code cell to access the datasets directly from your Drive. Remember to replace the placeholder paths with the actual paths to your files within your Google Drive."
      ],
      "id": "7af84e5b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cc76719"
      },
      "source": [
        "# Update the file paths to access data from Google Drive\n",
        "train_path = \"/content/drive/My Drive/census+income/adult.data\"  # Replace with your actual path\n",
        "test_path = \"/content/drive/My Drive/census+income/adult.test\"   # Replace with your actual path\n",
        "\n",
        "# Now, you can rerun the first code cell to load the data using these updated paths."
      ],
      "id": "0cc76719",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}