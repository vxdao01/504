{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "45fe0020-62b8-4b59-a26b-762c409d7b29",
      "metadata": {
        "id": "45fe0020-62b8-4b59-a26b-762c409d7b29"
      },
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# Final Team Project - Full Machine Learning Pipeline\n",
        "# ===========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix,\n",
        "    ConfusionMatrixDisplay, roc_curve, auc\n",
        ")\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or for zip files\n",
        "!wget https://github.com/vxdao01/504/tree/modeling/census-income\n",
        "!unzip census-income"
      ],
      "metadata": {
        "id": "2QfXXG3EDm8t",
        "outputId": "cc7e81f3-7d94-4734-8b65-d9e2ab9c03d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2QfXXG3EDm8t",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-04 03:54:25--  https://github.com/vxdao01/504/tree/modeling/census-income\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘census-income’\n",
            "\n",
            "census-income           [ <=>                ] 175.36K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-08-04 03:54:25 (1.75 MB/s) - ‘census-income’ saved [179571]\n",
            "\n",
            "Archive:  census-income\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of census-income or\n",
            "        census-income.zip, and cannot find census-income.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd\n",
        "# !ls\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/ADS-504-Final-Project')"
      ],
      "metadata": {
        "id": "8Er234YSlLGG"
      },
      "id": "8Er234YSlLGG",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW GOOGLE COLAB FILE PATHS ===\n",
        "train_path = \"/content/drive/My Drive/Colab Notebooks/ADS-504-Final-Project/adult.data\"\n",
        "test_path = \"/content/drive/My Drive/Colab Notebooks/ADS-504-Final-Project/adult.test\"\n",
        "\n",
        "# === FILE PATHS ===\n",
        "# train_path = r\"C:\\Users\\User\\Downloads\\census+income\\adult.data\"\n",
        "# test_path = r\"C:\\Users\\User\\Downloads\\census+income\\adult.test\""
      ],
      "metadata": {
        "id": "UePz9o0-mDSI"
      },
      "id": "UePz9o0-mDSI",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "71e2dc81-b244-44b9-a050-eb8722b0017d",
      "metadata": {
        "id": "71e2dc81-b244-44b9-a050-eb8722b0017d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5ca057-7bf2-4b83-c71b-68aa735bc622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 PROJECT INTRODUCTION:\n",
            "\n",
            "The goal of this project is to predict whether an individual earns more than $50K per year\n",
            "based on demographic and employment attributes from the UCI Adult Census dataset.\n",
            "\n",
            "This problem is important because it demonstrates how demographic and employment features\n",
            "can be leveraged to identify income patterns. Machine learning models can help in policy-making,\n",
            "targeted services, and socio-economic research by revealing key factors that influence income levels.\n",
            "\n",
            "\n",
            "✅ Dataset loaded successfully. Shape: (48842, 15)\n",
            "\n",
            "📊 Variable Descriptions:\n",
            "           Feature                                  Description         Type\n",
            "0              age                        Age of the individual      Numeric\n",
            "1        workclass                           Type of employment  Categorical\n",
            "2           fnlwgt  Census final weight (sample size indicator)      Numeric\n",
            "3        education          Highest level of education attained  Categorical\n",
            "4    education_num                 Number of years of education      Numeric\n",
            "5   marital_status                               Marital status  Categorical\n",
            "6       occupation                              Occupation type  Categorical\n",
            "7     relationship                          Relationship status  Categorical\n",
            "8             race                                         Race  Categorical\n",
            "9              sex                                       Gender  Categorical\n",
            "10    capital_gain                                 Capital gain      Numeric\n",
            "11    capital_loss                                 Capital loss      Numeric\n",
            "12  hours_per_week                Average hours worked per week      Numeric\n",
            "13  native_country                            Country of origin  Categorical\n",
            "14          income                 Income class (<=50K or >50K)       Target\n",
            "\n",
            "🧹 PREPROCESSING STARTED...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4135311693.py:60: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data cleaned. New shape: (48790, 15)\n"
          ]
        }
      ],
      "source": [
        "# === COLUMN NAMES ===\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
        "    \"hours_per_week\", \"native_country\", \"income\"\n",
        "]\n",
        "\n",
        "# === 1. DATASET INTRODUCTION ===\n",
        "print(\"📌 PROJECT INTRODUCTION:\")\n",
        "print(\"\"\"\n",
        "The goal of this project is to predict whether an individual earns more than $50K per year\n",
        "based on demographic and employment attributes from the UCI Adult Census dataset.\n",
        "\n",
        "This problem is important because it demonstrates how demographic and employment features\n",
        "can be leveraged to identify income patterns. Machine learning models can help in policy-making,\n",
        "targeted services, and socio-economic research by revealing key factors that influence income levels.\n",
        "\"\"\")\n",
        "\n",
        "# === LOAD DATA ===\n",
        "df_train = pd.read_csv(train_path, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "df_test = pd.read_csv(test_path, header=None, names=columns, na_values=\" ?\", skipinitialspace=True, comment='|', skiprows=1)\n",
        "df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "print(f\"\\n✅ Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "# === VARIABLE DESCRIPTIONS ===\n",
        "var_desc = pd.DataFrame({\n",
        "    \"Feature\": columns,\n",
        "    \"Description\": [\n",
        "        \"Age of the individual\",\n",
        "        \"Type of employment\",\n",
        "        \"Census final weight (sample size indicator)\",\n",
        "        \"Highest level of education attained\",\n",
        "        \"Number of years of education\",\n",
        "        \"Marital status\",\n",
        "        \"Occupation type\",\n",
        "        \"Relationship status\",\n",
        "        \"Race\",\n",
        "        \"Gender\",\n",
        "        \"Capital gain\",\n",
        "        \"Capital loss\",\n",
        "        \"Average hours worked per week\",\n",
        "        \"Country of origin\",\n",
        "        \"Income class (<=50K or >50K)\"\n",
        "    ],\n",
        "    \"Type\": [\"Numeric\", \"Categorical\", \"Numeric\", \"Categorical\", \"Numeric\", \"Categorical\",\n",
        "             \"Categorical\", \"Categorical\", \"Categorical\", \"Categorical\", \"Numeric\",\n",
        "             \"Numeric\", \"Numeric\", \"Categorical\", \"Target\"]\n",
        "})\n",
        "print(\"\\n📊 Variable Descriptions:\")\n",
        "print(var_desc)\n",
        "\n",
        "# === 2. PREPROCESSING ===\n",
        "print(\"\\n🧹 PREPROCESSING STARTED...\")\n",
        "\n",
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove extra spaces\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Fix target variable encoding\n",
        "df[\"income\"] = df[\"income\"].replace({\">50K.\": \">50K\", \"<=50K.\": \"<=50K\"}).map({\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "print(f\"✅ Data cleaned. New shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned raw dataset\n",
        "df.to_csv(r\"C:\\Users\\User\\Downloads\\census+income\\cleaned_raw_full.csv\", index=False)\n",
        "\n",
        "# === 3. EXPLORATORY DATA ANALYSIS (EDA) ===\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Income distribution\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.countplot(x=\"income\", data=df)\n",
        "plt.title(\"Income Distribution\")\n",
        "plt.show()\n",
        "print(\"\\n🔍 Insight: The dataset is imbalanced, with the majority earning <=50K.\")\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "print(\"🔍 Insight: Education_num, capital_gain, and hours_per_week have the strongest positive correlation with income.\")\n",
        "\n",
        "# === 4. ENCODING & SCALING ===\n",
        "df_encoded = pd.get_dummies(df, columns=[\n",
        "    \"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
        "    \"relationship\", \"race\", \"sex\", \"native_country\"\n",
        "])\n",
        "\n",
        "# Scale numeric features EXCEPT target\n",
        "numeric_cols = df_encoded.select_dtypes(include=np.number).columns.tolist()\n",
        "features_to_scale = [col for col in numeric_cols if col != \"income\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_encoded[features_to_scale] = scaler.fit_transform(df_encoded[features_to_scale])\n",
        "\n",
        "# Save modeling-ready dataset\n",
        "df_encoded.to_csv(r\"C:\\Users\\User\\Downloads\\census+income\\cleaned_data_encoded_scaled.csv\", index=False)\n",
        "\n",
        "# === 5. TRAIN/TEST SPLIT ===\n",
        "X = df_encoded.drop(\"income\", axis=1)\n",
        "y = df_encoded[\"income\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 6. MODELING & VALIDATION ===\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"CV Mean Accuracy\": cv_scores.mean(),\n",
        "        \"Test Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC\": auc_score\n",
        "    })\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"Cross-Validation Accuracy (Mean ± Std): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=[\"<=50K\", \">50K\"]).plot(\n",
        "        cmap='Blues' if name==\"Logistic Regression\" else 'Greens'\n",
        "    )\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc(fpr, tpr):.2f})\")\n",
        "\n",
        "# === 7. ROC Curve Comparison ===\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# === 8. MODEL PERFORMANCE COMPARISON TABLE ===\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n📊 Model Performance Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# === 9. BEST MODEL SELECTION & INSIGHTS ===\n",
        "best_model = results_df.sort_values(by=\"Test Accuracy\", ascending=False).iloc[0]\n",
        "print(f\"\\n✅ Best performing model: {best_model['Model']} \"\n",
        "      f\"with {best_model['Test Accuracy']:.4f} accuracy and {best_model['AUC']:.4f} AUC.\")\n",
        "print(\"💡 Insight: Logistic Regression is easier to interpret, \"\n",
        "      \"while Random Forest may capture complex feature interactions better.\")"
      ],
      "metadata": {
        "id": "PNfgveXI-85l"
      },
      "id": "PNfgveXI-85l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7af84e5b"
      },
      "source": [
        "After running the cell above and successfully mounting your Google Drive, run the following code to update the file paths in the first code cell to access the datasets directly from your Drive. Remember to replace the placeholder paths with the actual paths to your files within your Google Drive."
      ],
      "id": "7af84e5b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cc76719"
      },
      "source": [
        "# Update the file paths to access data from Google Drive\n",
        "train_path = \"/content/drive/My Drive/census+income/adult.data\"  # Replace with your actual path\n",
        "test_path = \"/content/drive/My Drive/census+income/adult.test\"   # Replace with your actual path\n",
        "\n",
        "# Now, you can rerun the first code cell to load the data using these updated paths."
      ],
      "id": "0cc76719",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}